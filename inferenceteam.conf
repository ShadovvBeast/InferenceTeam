[program:inferenceteam]
command=python3 /root/main.py
autostart=true
autorestart=true
stderr_logfile=/var/log/inferenceteam.err.log
stdout_logfile=/var/log/inferenceteam.out.log

[program:llamacpp]
command=/root/llama.cpp/build/bin/server -m /root/llama.cpp/models/dolphin-2.6-mistral-7b-dpo.Q5_K_S.gguf --n-gpu-layers 35 --ctx-size 16384 -cb -np 10 --api-key %(ENV_API_KEY)s --host ::
autostart=true
autorestart=true
stdout_logfile = /dev/stdout
stdout_logfile_maxbytes = 0
stderr_logfile = /dev/stderr
stderr_logfile_maxbytes = 0
